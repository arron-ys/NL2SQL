# NL2SQL Service 环境变量配置

# ============================================================
# 日志配置 (Logging Configuration)
# ============================================================
# 日志级别: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO



# ============================================================
# 流水线配置 (Pipeline Configuration), 用于日常的模型提交，服务调优,TUNING工作
# ============================================================
# 以下配置项有默认值，可根据需要覆盖
# 配置项名称使用下划线命名（pydantic-settings 会自动转换）

# 检索配置 (Retrieval Configuration)
# VECTOR_SEARCH_TOP_K=20
# MAX_TERM_RECALL=20
# SIMILARITY_THRESHOLD=0.4

# 验证配置 (Validation Configuration)
# DEFAULT_LIMIT=100
# MAX_LIMIT_CAP=1000

# 执行配置 (Execution Configuration)
# EXECUTION_TIMEOUT_MS=5000
# MAX_RESULT_ROWS=5000

# LLM 配置 (LLM Configuration)
# MAX_LLM_ROWS=50


# ============================================================
# 默认LLM模型：DeepSeek
# ============================================================
# 如优先用你显式设置的 DEFAULT_LLM_PROVIDER
# DEFAULT_LLM_PROVIDER=deepseek
# 如果没配置（或配置无效），才走自动选择，现在的优先级是：DeepSeek > Qwen > OpenAI，但前提是对应的 API_KEY 存在


# ============================================================
# LLM 配置 (LLM Configuration)
# ============================================================

# 默认LLM模型：优先用下方显式设置的 DEFAULT_LLM_PROVIDER
# 如果没配置（或配置无效），才走自动选择，现在的优先级是：DeepSeek > Qwen > OpenAI，但前提是对应的 API_KEY 存在
# DEFAULT_LLM_PROVIDER=deepseek


# 通用超时配置 (General Timeout Configuration)
# 通用 LLM 超时配置（所有 LLM provider 都使用，除非设置了 provider 特定超时）
# 默认值：60.0 秒（OpenAI/DeepSeek/Qwen），30.0 秒（Jina）
LLM_TIMEOUT=60.0

# OpenAI API Key (必需)
OPENAI_API_KEY=

# OpenAI Base URL (可选，用于自定义 API 端点，如使用代理)
# 如果不设置，将使用 OpenAI 官方 API
OPENAI_BASE_URL=

# OpenAI 模型配置 (可选，不设置则使用默认值)
# 查询分解模型 (默认: gpt-4o-mini)
# 可选值: gpt-4o-mini, gpt-4o, gpt-4-turbo, gpt-3.5-turbo 等
OPENAI_MODEL_QUERY_DECOMPOSITION=gpt-4o-mini

# 计划生成模型 (默认: gpt-4o-mini)
# 可选值: gpt-4o-mini, gpt-4o, gpt-4-turbo, gpt-3.5-turbo 等
OPENAI_MODEL_PLAN_GENERATION=gpt-4o-mini

# 答案生成模型 (默认: gpt-4o-mini)
# 可选值: gpt-4o-mini, gpt-4o, gpt-4-turbo, gpt-3.5-turbo 等
OPENAI_MODEL_ANSWER_GENERATION=gpt-4o-mini

# OpenAI 超时配置 (可选，默认: 60 秒)
# OPENAI_TIMEOUT=60.0  # 可选，如果设置了会覆盖 LLM_TIMEOUT



# ============================================================
# DeepSeek 配置 (DeepSeek Configuration)
# ============================================================
# DeepSeek API Key (可选，如果使用 DeepSeek 模型)
# DeepSeek 使用 OpenAI 兼容的 API 接口
DEEPSEEK_API_KEY=

# DeepSeek Base URL (可选，默认值为 https://api.deepseek.com)
DEEPSEEK_BASE_URL=https://api.deepseek.com

# DeepSeek 模型配置 (可选，不设置则使用默认值)
# 查询分解模型 (默认: deepseek-chat)
DEEPSEEK_MODEL_QUERY_DECOMPOSITION=deepseek-chat

# 计划生成模型 (默认: deepseek-reasoner，推理模型)
DEEPSEEK_MODEL_PLAN_GENERATION=deepseek-reasoner

# 答案生成模型 (默认: deepseek-chat)
DEEPSEEK_MODEL_ANSWER_GENERATION=deepseek-chat

# DeepSeek 超时配置 (可选，如果设置了会覆盖 LLM_TIMEOUT)
# DEEPSEEK_TIMEOUT=60.0

# ============================================================
# Qwen 配置 (Qwen Configuration)
# ============================================================
# Qwen API Key (可选，如果使用 Qwen 模型)
# Qwen 使用 OpenAI 兼容的 API 接口（通过阿里云 DashScope）
QWEN_API_KEY=

# Qwen Base URL (可选，默认值为 https://dashscope.aliyuncs.com/compatible-mode/v1)
QWEN_BASE_URL=https://dashscope.aliyuncs.com/compatible-mode/v1

# Qwen 模型配置 (可选，不设置则使用默认值)
# 查询分解模型 (默认: qwen-turbo，快速)
QWEN_MODEL_QUERY_DECOMPOSITION=qwen-turbo

# 计划生成模型 (默认: qwen-max，高质量)
QWEN_MODEL_PLAN_GENERATION=qwen-max

# 答案生成模型 (默认: qwen-plus，平衡)
QWEN_MODEL_ANSWER_GENERATION=qwen-plus

# Qwen 超时配置 (可选，如果设置了会覆盖 LLM_TIMEOUT)
# QWEN_TIMEOUT=60.0

# ============================================================
# Jina 配置 (Jina Configuration)
# ============================================================
# Jina AI Embedding API Key (用于生成文本嵌入向量)
# 如果不设置，向量搜索功能将不可用
JINA_API_KEY=

# Jina Base URL (可选，Jina 有默认的 base_url)
JINA_BASE_URL=

# Jina 超时配置 (可选，如果设置了会覆盖 LLM_TIMEOUT)
# 默认值：30.0 秒
JINA_TIMEOUT=30.0

# Jina 模型配置 (可选，不设置则使用默认值)
# 嵌入模型 (默认: jina-embeddings-v3)
# 可选值: jina-embeddings-v3, jina-embeddings-v2 等
JINA_MODEL_EMBEDDING=jina-embeddings-v3

# ============================================================
# 向量数据库配置 (Vector Database Configuration)
# ============================================================

# 向量存储模式：local（本地文件系统，默认）/ memory（内存）/ remote（远程服务）
# 默认值：local
VECTOR_STORE_MODE=local

# 本地存储路径（仅 local 模式有效）
# 如果未设置，默认使用项目根目录下的 qdrant_data/ 文件夹
# 示例：VECTOR_STORE_PATH=../qdrant_data
# VECTOR_STORE_PATH=

# Qdrant 远程服务配置（仅 remote 模式有效）
# 方式1：使用 URL（推荐）
# QDRANT_URL=http://localhost:6333

# 方式2：使用 Host + Port（向后兼容）
QDRANT_HOST=localhost
QDRANT_PORT=6333
# QDRANT_API_KEY=  # 可选，如果 Qdrant 需要认证

# ============================================================
# 语义层配置 (Semantics Configuration)
# ============================================================
# YAML 配置文件目录路径（相对于项目根目录）
# 默认值为 "semantics"
SEMANTICS_YAML_PATH=semantics


# 数据库配置 (Database Configuration)
# ============================================================
# 数据库类型: mysql 或 postgresql
DB_TYPE=mysql

# MySQL/PostgreSQL 连接配置
DB_HOST=localhost
DB_PORT=3306
DB_USER=root
DB_PASSWORD=
DB_NAME=

# ============================================================
# 网络（代理）配置 (Proxy Configuration)
# ============================================================
# 说明：
# - 默认不信任系统代理环境变量（HTTP_PROXY/HTTPS_PROXY/ALL_PROXY），除非显式设置 PROXY_MODE=system
# - OpenAI / DeepSeek / Qwen 分别使用各自的 *_PROXY，避免互相污染
#
# PROXY_MODE:
# - none:    禁用所有代理（强制直连），忽略系统代理 env（trust_env=False）
# - explicit:（默认/推荐）仅使用 provider 专用代理（*_PROXY），忽略系统代理 env（trust_env=False）
# - system:  信任系统代理 env（HTTP_PROXY/HTTPS_PROXY/ALL_PROXY），即 trust_env=True
PROXY_MODE=explicit
#
# PROXY_STRICT:
# - 0（默认）: 显式代理不可达则自动降级直连，并强制 trust_env=False（避免再次被系统代理 env 劫持）
# - 1        : 显式代理不可达则直接报错（用于快速定位端口/进程问题）
PROXY_STRICT=0
#
# Provider 专用代理（仅在 PROXY_MODE=explicit 时使用）
OPENAI_PROXY=http://127.0.0.1:7897
DEEPSEEK_PROXY=
QWEN_PROXY=
#
# 系统级代理（仅在 PROXY_MODE=system 时才会生效）
HTTP_PROXY=
HTTPS_PROXY=
# <<< PROXY_CONFIG_SECTION




